{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e77b19",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "This notebook covers:\n",
    "1. Load raw data\n",
    "2. Text cleaning functions\n",
    "3. Tokenization logic\n",
    "4. Vocabulary creation\n",
    "5. Padding / truncation\n",
    "6. Save processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112a368",
   "metadata": {},
   "source": [
    "## 1. Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6131c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (16000, 2)\n",
      "Test shape: (2000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "train_df = pd.read_csv(DATA_DIR / \"train.txt\", sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
    "test_df = pd.read_csv(DATA_DIR / \"test.txt\", sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ffc3d6",
   "metadata": {},
   "source": [
    "## 2. Text cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba181ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: i didnt feel humiliated\n",
      "Clean: i didnt feel humiliated\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "sample_text = train_df.loc[0, \"text\"]\n",
    "print(\"Raw:\", sample_text)\n",
    "print(\"Clean:\", clean_text(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590abd6c",
   "metadata": {},
   "source": [
    "## 3. Tokenization logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8edb81b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>[i, didnt, feel, humiliated]</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>[i, can, go, from, feeling, so, hopeless, to, ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>[im, grabbing, a, minute, to, post, i, feel, g...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>[i, am, ever, feeling, nostalgic, about, the, ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>[i, am, feeling, grouchy]</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                            i didnt feel humiliated   \n",
       "1  i can go from feeling so hopeless to so damned...   \n",
       "2   im grabbing a minute to post i feel greedy wrong   \n",
       "3  i am ever feeling nostalgic about the fireplac...   \n",
       "4                               i am feeling grouchy   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                            i didnt feel humiliated   \n",
       "1  i can go from feeling so hopeless to so damned...   \n",
       "2   im grabbing a minute to post i feel greedy wrong   \n",
       "3  i am ever feeling nostalgic about the fireplac...   \n",
       "4                               i am feeling grouchy   \n",
       "\n",
       "                                              tokens  emotion  \n",
       "0                       [i, didnt, feel, humiliated]  sadness  \n",
       "1  [i, can, go, from, feeling, so, hopeless, to, ...  sadness  \n",
       "2  [im, grabbing, a, minute, to, post, i, feel, g...    anger  \n",
       "3  [i, am, ever, feeling, nostalgic, about, the, ...     love  \n",
       "4                          [i, am, feeling, grouchy]    anger  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text: str) -> list[str]:\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
    "test_df[\"clean_text\"] = test_df[\"text\"].apply(clean_text)\n",
    "\n",
    "train_df[\"tokens\"] = train_df[\"clean_text\"].apply(tokenize)\n",
    "test_df[\"tokens\"] = test_df[\"clean_text\"].apply(tokenize)\n",
    "\n",
    "train_df[[\"text\", \"clean_text\", \"tokens\", \"emotion\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57b610",
   "metadata": {},
   "source": [
    "## 4. Vocabulary creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3326c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 7401\n",
      "First 20 tokens: ['<PAD>', '<UNK>', 'i', 'feel', 'and', 'to', 'the', 'a', 'feeling', 'that', 'of', 'my', 'in', 'it', 'like', 'so', 'for', 'im', 'me', 'but']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def build_vocab(token_lists: pd.Series, min_freq: int = 2) -> dict[str, int]:\n",
    "    counter = Counter(token for tokens in token_lists for token in tokens)\n",
    "    kept_tokens = [tok for tok, freq in counter.items() if freq >= min_freq]\n",
    "    kept_tokens = sorted(kept_tokens, key=lambda t: (-counter[t], t))\n",
    "\n",
    "    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "    for token in kept_tokens:\n",
    "        vocab[token] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "\n",
    "vocab = build_vocab(train_df[\"tokens\"], min_freq=2)\n",
    "print(f\"Vocab size: {len(vocab)}\")\n",
    "print(\"First 20 tokens:\", list(vocab.keys())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bfbe9",
   "metadata": {},
   "source": [
    "## 5. Padding / truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a64352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length (95th percentile): 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, didnt, feel, humiliated]</td>\n",
       "      <td>[2, 139, 3, 686, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i, can, go, from, feeling, so, hopeless, to, ...</td>\n",
       "      <td>[2, 40, 101, 60, 8, 15, 497, 5, 15, 3642, 557,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[im, grabbing, a, minute, to, post, i, feel, g...</td>\n",
       "      <td>[17, 3239, 7, 1165, 5, 288, 2, 3, 496, 448, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[i, am, ever, feeling, nostalgic, about, the, ...</td>\n",
       "      <td>[2, 24, 165, 8, 671, 27, 6, 4517, 2, 59, 48, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, am, feeling, grouchy]</td>\n",
       "      <td>[2, 24, 8, 1075, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0                       [i, didnt, feel, humiliated]   \n",
       "1  [i, can, go, from, feeling, so, hopeless, to, ...   \n",
       "2  [im, grabbing, a, minute, to, post, i, feel, g...   \n",
       "3  [i, am, ever, feeling, nostalgic, about, the, ...   \n",
       "4                          [i, am, feeling, grouchy]   \n",
       "\n",
       "                                           input_ids  \n",
       "0  [2, 139, 3, 686, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1  [2, 40, 101, 60, 8, 15, 497, 5, 15, 3642, 557,...  \n",
       "2  [17, 3239, 7, 1165, 5, 288, 2, 3, 496, 448, 0,...  \n",
       "3  [2, 24, 165, 8, 671, 27, 6, 4517, 2, 59, 48, 9...  \n",
       "4  [2, 24, 8, 1075, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_tokens(tokens: list[str], vocab_map: dict[str, int]) -> list[int]:\n",
    "    unk_id = vocab_map[\"<UNK>\"]\n",
    "    return [vocab_map.get(token, unk_id) for token in tokens]\n",
    "\n",
    "\n",
    "def pad_or_truncate(ids: list[int], max_len: int, pad_id: int = 0) -> list[int]:\n",
    "    if len(ids) > max_len:\n",
    "        return ids[:max_len]\n",
    "    return ids + [pad_id] * (max_len - len(ids))\n",
    "\n",
    "\n",
    "train_lengths = train_df[\"tokens\"].apply(len)\n",
    "max_len = int(train_lengths.quantile(0.95))\n",
    "print(f\"Max length (95th percentile): {max_len}\")\n",
    "\n",
    "train_df[\"input_ids\"] = train_df[\"tokens\"].apply(lambda t: encode_tokens(t, vocab))\n",
    "test_df[\"input_ids\"] = test_df[\"tokens\"].apply(lambda t: encode_tokens(t, vocab))\n",
    "\n",
    "train_df[\"input_ids\"] = train_df[\"input_ids\"].apply(lambda ids: pad_or_truncate(ids, max_len))\n",
    "test_df[\"input_ids\"] = test_df[\"input_ids\"].apply(lambda ids: pad_or_truncate(ids, max_len))\n",
    "\n",
    "train_df[[\"tokens\", \"input_ids\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44e1460",
   "metadata": {},
   "source": [
    "## 6. Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b74f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "- ../data/processed/train_processed.csv\n",
      "- ../data/processed/test_processed.csv\n",
      "- ../data/processed/vocab.json\n",
      "- ../data/processed/metadata.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def ids_to_string(ids: list[int]) -> str:\n",
    "    return \" \".join(str(i) for i in ids)\n",
    "\n",
    "\n",
    "output_dir = DATA_DIR / \"processed\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_out = train_df.copy()\n",
    "test_out = test_df.copy()\n",
    "\n",
    "train_out[\"input_ids\"] = train_out[\"input_ids\"].apply(ids_to_string)\n",
    "test_out[\"input_ids\"] = test_out[\"input_ids\"].apply(ids_to_string)\n",
    "\n",
    "train_out[[\"input_ids\", \"emotion\"]].to_csv(output_dir / \"train_processed.csv\", index=False)\n",
    "test_out[[\"input_ids\", \"emotion\"]].to_csv(output_dir / \"test_processed.csv\", index=False)\n",
    "\n",
    "with open(output_dir / \"vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab, f, indent=2)\n",
    "\n",
    "metadata = {\"max_len\": max_len, \"vocab_size\": len(vocab)}\n",
    "with open(output_dir / \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", output_dir / \"train_processed.csv\")\n",
    "print(\"-\", output_dir / \"test_processed.csv\")\n",
    "print(\"-\", output_dir / \"vocab.json\")\n",
    "print(\"-\", output_dir / \"metadata.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
