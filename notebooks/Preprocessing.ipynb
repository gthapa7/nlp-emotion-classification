{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44e77b19",
        "language": "markdown"
      },
      "source": [
        "# Text Preprocessing\n",
        "\n",
        "This notebook covers:\n",
        "1. Load raw data\n",
        "2. Text cleaning functions\n",
        "3. Tokenization logic\n",
        "4. Vocabulary creation\n",
        "5. Padding / truncation\n",
        "6. Save processed data"
      ],
      "id": "44e77b19"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6112a368",
        "language": "markdown"
      },
      "source": [
        "## 1. Load raw data"
      ],
      "id": "6112a368"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e6131c3",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "DATA_DIR = Path(\"../data\")\n",
        "\n",
        "train_df = pd.read_csv(DATA_DIR / \"train.txt\", sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
        "test_df = pd.read_csv(DATA_DIR / \"test.txt\", sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
        "\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "\n",
        "train_df.head()"
      ],
      "id": "2e6131c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38ffc3d6",
        "language": "markdown"
      },
      "source": [
        "## 2. Text cleaning functions"
      ],
      "id": "38ffc3d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba181ca7",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "sample_text = train_df.loc[0, \"text\"]\n",
        "print(\"Raw:\", sample_text)\n",
        "print(\"Clean:\", clean_text(sample_text))"
      ],
      "id": "ba181ca7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "590abd6c",
        "language": "markdown"
      },
      "source": [
        "## 3. Tokenization logic"
      ],
      "id": "590abd6c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8edb81b6",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "def tokenize(text: str) -> list[str]:\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
        "test_df[\"clean_text\"] = test_df[\"text\"].apply(clean_text)\n",
        "\n",
        "train_df[\"tokens\"] = train_df[\"clean_text\"].apply(tokenize)\n",
        "test_df[\"tokens\"] = test_df[\"clean_text\"].apply(tokenize)\n",
        "\n",
        "train_df[[\"text\", \"clean_text\", \"tokens\", \"emotion\"]].head()"
      ],
      "id": "8edb81b6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a57b610",
        "language": "markdown"
      },
      "source": [
        "## 4. Vocabulary creation"
      ],
      "id": "0a57b610"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3326c94",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "def build_vocab(token_lists: pd.Series, min_freq: int = 2) -> dict[str, int]:\n",
        "    counter = Counter(token for tokens in token_lists for token in tokens)\n",
        "    kept_tokens = [tok for tok, freq in counter.items() if freq >= min_freq]\n",
        "    kept_tokens = sorted(kept_tokens, key=lambda t: (-counter[t], t))\n",
        "\n",
        "    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "    for token in kept_tokens:\n",
        "        vocab[token] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "\n",
        "vocab = build_vocab(train_df[\"tokens\"], min_freq=2)\n",
        "print(f\"Vocab size: {len(vocab)}\")\n",
        "print(\"First 20 tokens:\", list(vocab.keys())[:20])"
      ],
      "id": "d3326c94"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "554bfbe9",
        "language": "markdown"
      },
      "source": [
        "## 5. Padding / truncation"
      ],
      "id": "554bfbe9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58a64352",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "def encode_tokens(tokens: list[str], vocab_map: dict[str, int]) -> list[int]:\n",
        "    unk_id = vocab_map[\"<UNK>\"]\n",
        "    return [vocab_map.get(token, unk_id) for token in tokens]\n",
        "\n",
        "\n",
        "def pad_or_truncate(ids: list[int], max_len: int, pad_id: int = 0) -> list[int]:\n",
        "    if len(ids) > max_len:\n",
        "        return ids[:max_len]\n",
        "    return ids + [pad_id] * (max_len - len(ids))\n",
        "\n",
        "\n",
        "train_lengths = train_df[\"tokens\"].apply(len)\n",
        "max_len = int(train_lengths.quantile(0.95))\n",
        "print(f\"Max length (95th percentile): {max_len}\")\n",
        "\n",
        "train_df[\"input_ids\"] = train_df[\"tokens\"].apply(lambda t: encode_tokens(t, vocab))\n",
        "test_df[\"input_ids\"] = test_df[\"tokens\"].apply(lambda t: encode_tokens(t, vocab))\n",
        "\n",
        "train_df[\"input_ids\"] = train_df[\"input_ids\"].apply(lambda ids: pad_or_truncate(ids, max_len))\n",
        "test_df[\"input_ids\"] = test_df[\"input_ids\"].apply(lambda ids: pad_or_truncate(ids, max_len))\n",
        "\n",
        "train_df[[\"tokens\", \"input_ids\"]].head()"
      ],
      "id": "58a64352"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a44e1460",
        "language": "markdown"
      },
      "source": [
        "## 6. Save processed data"
      ],
      "id": "a44e1460"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3b74f2f",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def ids_to_string(ids: list[int]) -> str:\n",
        "    return \" \".join(str(i) for i in ids)\n",
        "\n",
        "\n",
        "output_dir = DATA_DIR / \"processed\"\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_out = train_df.copy()\n",
        "test_out = test_df.copy()\n",
        "\n",
        "train_out[\"input_ids\"] = train_out[\"input_ids\"].apply(ids_to_string)\n",
        "test_out[\"input_ids\"] = test_out[\"input_ids\"].apply(ids_to_string)\n",
        "\n",
        "train_out[[\"input_ids\", \"emotion\"]].to_csv(output_dir / \"train_processed.csv\", index=False)\n",
        "test_out[[\"input_ids\", \"emotion\"]].to_csv(output_dir / \"test_processed.csv\", index=False)\n",
        "\n",
        "with open(output_dir / \"vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(vocab, f, indent=2)\n",
        "\n",
        "metadata = {\"max_len\": max_len, \"vocab_size\": len(vocab)}\n",
        "with open(output_dir / \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\"-\", output_dir / \"train_processed.csv\")\n",
        "print(\"-\", output_dir / \"test_processed.csv\")\n",
        "print(\"-\", output_dir / \"vocab.json\")\n",
        "print(\"-\", output_dir / \"metadata.json\")"
      ],
      "id": "f3b74f2f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}