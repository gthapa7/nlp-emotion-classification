{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "def5766f",
        "language": "markdown"
      },
      "source": [
        "# Model 1: Fully Connected Neural Network \n",
        "\n",
        "This notebook builds a simple FCNN baseline for emotion classification. It compares two feature types (Bag-of-Words and TF-IDF) using the same preprocessing and training setup, then reports metrics and learning curves.\n",
        "\n",
        "Goals:\n",
        "- Keep preprocessing consistent\n",
        "- Train FCNN baselines\n",
        "- Compare BoW vs TF-IDF\n",
        "- Save results for later comparison"
      ],
      "id": "def5766f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bf031b6",
        "language": "markdown"
      },
      "source": [
        "## 1. Load preprocessed data"
      ],
      "id": "4bf031b6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "970180d9",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "DATA_DIR = Path(\"../data\")\n",
        "\n",
        "train_df = pd.read_csv(DATA_DIR / \"train.txt\", sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
        "test_df = pd.read_csv(DATA_DIR / \"test.txt\", sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
        "\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "\n",
        "train_df.head()"
      ],
      "id": "970180d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba95fef3",
        "language": "markdown"
      },
      "source": [
        "## 2. Bag-of-Words features (tokenization + one-hot)"
      ],
      "id": "ba95fef3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb41dbcd",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
        "test_df[\"clean_text\"] = test_df[\"text\"].apply(clean_text)\n",
        "\n",
        "vectorizer = CountVectorizer(min_df=2, max_df=0.95)\n",
        "X_train = vectorizer.fit_transform(train_df[\"clean_text\"])\n",
        "X_test = vectorizer.transform(test_df[\"clean_text\"])\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_df[\"emotion\"])\n",
        "y_test = label_encoder.transform(test_df[\"emotion\"])\n",
        "class_names = list(label_encoder.classes_)\n",
        "\n",
        "X_train_dense = X_train.toarray().astype(\"float32\")\n",
        "X_test_dense = X_test.toarray().astype(\"float32\")\n",
        "num_classes = len(class_names)\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "print(f\"BoW train shape: {X_train.shape}\")\n",
        "print(f\"Dense train shape: {X_train_dense.shape}\")\n",
        "print(f\"Classes: {class_names}\")"
      ],
      "id": "fb41dbcd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b687a22",
        "language": "markdown"
      },
      "source": [
        "## 3. Model definition"
      ],
      "id": "8b687a22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4e4707c",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "regularizer = tf.keras.regularizers.l2(1e-4)\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=(X_train_dense.shape[1],)),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=regularizer),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizer),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "id": "f4e4707c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "957ade0e",
        "language": "markdown"
      },
      "source": [
        "## 4. Training"
      ],
      "id": "957ade0e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40f094d3",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=2,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_dense,\n",
        "    y_train_cat,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1,\n",
        ")"
      ],
      "id": "40f094d3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d57c121",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"BoW FCNN Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"BoW FCNN Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "7d57c121"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91e13bd1",
        "language": "markdown"
      },
      "source": [
        "**BoW training curves (interpretation)**\n",
        "- Training loss drops quickly while validation loss flattens, so the model learns fast and then starts to overfit.\n",
        "- Validation accuracy stabilizes around the high 0.8s, which suggests the baseline is solid but not improving after a few epochs.\n",
        "- Early stopping is appropriate to avoid unnecessary epochs once validation stops improving."
      ],
      "id": "91e13bd1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3337abe",
        "language": "markdown"
      },
      "source": [
        "## 5. Evaluation on test set"
      ],
      "id": "a3337abe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01526165",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "\n",
        "probs = model.predict(X_test_dense)\n",
        "y_pred = probs.argmax(axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    y_test, y_pred, average=\"macro\", zero_division=0\n",
        ")\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (macro): {precision:.4f}\")\n",
        "print(f\"Recall (macro): {recall:.4f}\")\n",
        "print(f\"F1 (macro): {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=class_names, zero_division=0))"
      ],
      "id": "01526165"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3eebda0",
        "language": "markdown"
      },
      "source": [
        "## 6. Save metrics"
      ],
      "id": "d3eebda0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a0d1ec8",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "results_dir = Path(\"../results\")\n",
        "results_dir.mkdir(parents=True, exist_ok=True)\n",
        "metrics_path = results_dir / \"metrics.csv\"\n",
        "\n",
        "row = {\n",
        "    \"model\": \"FC_BOW\",\n",
        "    \"accuracy\": round(accuracy, 4),\n",
        "    \"precision\": round(precision, 4),\n",
        "    \"recall\": round(recall, 4),\n",
        "    \"f1\": round(f1, 4),\n",
        "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame([row])\n",
        "\n",
        "if metrics_path.exists():\n",
        "    metrics_df.to_csv(metrics_path, mode=\"a\", header=False, index=False)\n",
        "else:\n",
        "    metrics_df.to_csv(metrics_path, index=False)\n",
        "\n",
        "print(f\"Saved metrics to: {metrics_path}\")\n",
        "metrics_df"
      ],
      "id": "6a0d1ec8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "045b1c06",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "val_path = Path(\"../data/validation.txt\")\n",
        "if val_path.exists():\n",
        "    val_df = pd.read_csv(val_path, sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
        "    val_df[\"clean_text\"] = val_df[\"text\"].apply(clean_text)\n",
        "    X_val = vectorizer.transform(val_df[\"clean_text\"]).toarray().astype(\"float32\")\n",
        "    y_val = label_encoder.transform(val_df[\"emotion\"])\n",
        "    val_probs = model.predict(X_val)\n",
        "    val_pred = val_probs.argmax(axis=1)\n",
        "    val_accuracy = accuracy_score(y_val, val_pred)\n",
        "    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n",
        "        y_val, val_pred, average=\"macro\", zero_division=0\n",
        "    )\n",
        "\n",
        "    print(\"Validation metrics (BoW):\")\n",
        "    print(f\"Accuracy: {val_accuracy:.4f}\")\n",
        "    print(f\"Precision (macro): {val_precision:.4f}\")\n",
        "    print(f\"Recall (macro): {val_recall:.4f}\")\n",
        "    print(f\"F1 (macro): {val_f1:.4f}\")\n",
        "\n",
        "    val_row = {\n",
        "        \"model\": \"FC_BOW_VAL\",\n",
        "        \"accuracy\": round(val_accuracy, 4),\n",
        "        \"precision\": round(val_precision, 4),\n",
        "        \"recall\": round(val_recall, 4),\n",
        "        \"f1\": round(val_f1, 4),\n",
        "        \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "    }\n",
        "\n",
        "    val_metrics_df = pd.DataFrame([val_row])\n",
        "    if metrics_path.exists():\n",
        "        val_metrics_df.to_csv(metrics_path, mode=\"a\", header=False, index=False)\n",
        "    else:\n",
        "        val_metrics_df.to_csv(metrics_path, index=False)\n",
        "\n",
        "    val_metrics_df"
      ],
      "id": "045b1c06"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25e2390d",
        "language": "markdown"
      },
      "source": [
        "## 7. TF-IDF baseline (Keras)"
      ],
      "id": "25e2390d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70dbef54",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer_tfidf = TfidfVectorizer(min_df=2, max_df=0.95)\n",
        "X_train_tfidf = vectorizer_tfidf.fit_transform(train_df[\"clean_text\"])\n",
        "X_test_tfidf = vectorizer_tfidf.transform(test_df[\"clean_text\"])\n",
        "\n",
        "X_train_tfidf_dense = X_train_tfidf.toarray().astype(\"float32\")\n",
        "X_test_tfidf_dense = X_test_tfidf.toarray().astype(\"float32\")\n",
        "\n",
        "print(f\"TF-IDF train shape: {X_train_tfidf.shape}\")"
      ],
      "id": "70dbef54"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e44958ad",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "tfidf_model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=(X_train_tfidf_dense.shape[1],)),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "tfidf_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "tfidf_model.summary()"
      ],
      "id": "e44958ad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a7488e3",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "tfidf_history = tfidf_model.fit(\n",
        "    X_train_tfidf_dense,\n",
        "    y_train_cat,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1,\n",
        ")"
      ],
      "id": "8a7488e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b87be314",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(tfidf_history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(tfidf_history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"TF-IDF FCNN Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(tfidf_history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(tfidf_history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"TF-IDF FCNN Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "b87be314"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c35d32a",
        "language": "markdown"
      },
      "source": [
        "**TF-IDF training curves (interpretation)**\n",
        "- Training loss decreases steadily, while validation loss levels off, indicating mild overfitting after the first few epochs.\n",
        "- Validation accuracy improves early and then plateaus, so the best checkpoint is usually near the first few epochs.\n",
        "- Early stopping helps keep the model near its best generalization point."
      ],
      "id": "9c35d32a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44442c22",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "\n",
        "tfidf_probs = tfidf_model.predict(X_test_tfidf_dense)\n",
        "tfidf_pred = tfidf_probs.argmax(axis=1)\n",
        "\n",
        "tfidf_accuracy = accuracy_score(y_test, tfidf_pred)\n",
        "tfidf_precision, tfidf_recall, tfidf_f1, _ = precision_recall_fscore_support(\n",
        "    y_test, tfidf_pred, average=\"macro\", zero_division=0\n",
        ")\n",
        "\n",
        "print(f\"TF-IDF Accuracy: {tfidf_accuracy:.4f}\")\n",
        "print(f\"TF-IDF Precision (macro): {tfidf_precision:.4f}\")\n",
        "print(f\"TF-IDF Recall (macro): {tfidf_recall:.4f}\")\n",
        "print(f\"TF-IDF F1 (macro): {tfidf_f1:.4f}\")\n",
        "\n",
        "print(\"\\nTF-IDF Classification report:\\n\")\n",
        "print(classification_report(y_test, tfidf_pred, target_names=class_names, zero_division=0))"
      ],
      "id": "44442c22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30a99bee",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "tfidf_row = {\n",
        "    \"model\": \"FC_TFIDF\",\n",
        "    \"accuracy\": round(tfidf_accuracy, 4),\n",
        "    \"precision\": round(tfidf_precision, 4),\n",
        "    \"recall\": round(tfidf_recall, 4),\n",
        "    \"f1\": round(tfidf_f1, 4),\n",
        "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "}\n",
        "\n",
        "tfidf_metrics_df = pd.DataFrame([tfidf_row])\n",
        "\n",
        "if metrics_path.exists():\n",
        "    tfidf_metrics_df.to_csv(metrics_path, mode=\"a\", header=False, index=False)\n",
        "else:\n",
        "    tfidf_metrics_df.to_csv(metrics_path, index=False)\n",
        "\n",
        "print(f\"Saved TF-IDF metrics to: {metrics_path}\")\n",
        "tfidf_metrics_df"
      ],
      "id": "30a99bee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fcd8e5d",
        "language": "markdown"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we trained FCNN baselines with Bag-of-Words and TF-IDF features using the same preprocessing. We experimented with regularization (extra layers, dropout, L2) to control overfitting. For TF-IDF, heavier regularization hurt performance, so we reverted to a simpler architecture. The final models use stable settings and provide solid baseline metrics for later comparison."
      ],
      "id": "0fcd8e5d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfc31848",
        "language": "markdown"
      },
      "source": [
        "## Metrics Insights\n",
        "\n",
        "- BoW achieves slightly stronger macro F1 than TF-IDF, which suggests better balance across classes on this dataset.\n",
        "- Both models perform well on frequent classes (joy, sadness) while rare classes (surprise, love) remain harder.\n",
        "- The gap between accuracy and macro F1 indicates class imbalance, so macro F1 is the more reliable comparison metric."
      ],
      "id": "cfc31848"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}