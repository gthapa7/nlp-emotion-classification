{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caf9a00416ef43d7a37f82fddd89bc00",
   "metadata": {
    "id": "caf9a00416ef43d7a37f82fddd89bc00",
    "language": "markdown"
   },
   "source": [
    "# Model 2: RNN (LSTM)\n",
    "\n",
    "This notebook follows the Course 3 workflow:\n",
    "Tokenized Text Sequences → Embedding → LSTM → Dense → Softmax\n",
    "\n",
    "Steps:\n",
    "1. Load preprocessed sequences\n",
    "2. Define embedding + RNN model\n",
    "3. Train the model\n",
    "4. Evaluate on test set\n",
    "5. Save metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291c20a615b492c8f66704f35b6348a",
   "metadata": {
    "id": "8291c20a615b492c8f66704f35b6348a",
    "language": "markdown"
   },
   "source": [
    "## 1. Load and preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f9d543c00416caf991dcd33a6a41c",
   "metadata": {
    "id": "578f9d543c00416caf991dcd33a6a41c",
    "language": "code"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "train_df = pd.read_csv(DATA_DIR / \"train.txt\", sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
    "test_df = pd.read_csv(DATA_DIR / \"test.txt\", sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
    "test_df[\"clean_text\"] = test_df[\"text\"].apply(clean_text)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6d42a2bb5492894c88b347f454b40",
   "metadata": {
    "id": "6fb6d42a2bb5492894c88b347f454b40",
    "language": "markdown"
   },
   "source": [
    "## 2. Tokenize and pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1a3d5686641a68ef75be8d2e98614",
   "metadata": {
    "id": "69e1a3d5686641a68ef75be8d2e98614",
    "language": "code"
   },
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "\n",
    "text_tokenizer = Tokenizer(num_words=max_words, oov_token=\"<UNK>\")\n",
    "text_tokenizer.fit_on_texts(train_df[\"clean_text\"])\n",
    "\n",
    "train_seq = text_tokenizer.texts_to_sequences(train_df[\"clean_text\"])\n",
    "test_seq = text_tokenizer.texts_to_sequences(test_df[\"clean_text\"])\n",
    "\n",
    "seq_lengths = np.array([len(seq) for seq in train_seq])\n",
    "max_len = int(np.percentile(seq_lengths, 95))\n",
    "\n",
    "X_train = pad_sequences(train_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "X_test = pad_sequences(test_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_df[\"emotion\"])\n",
    "y_test = label_encoder.transform(test_df[\"emotion\"])\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "print(f\"Vocab size (limited): {max_words}\")\n",
    "print(f\"Sequence length (95th percentile): {max_len}\")\n",
    "print(f\"Train sequences shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9946b285d4cf9b4c4c0aaac7f99d6",
   "metadata": {
    "id": "d1c9946b285d4cf9b4c4c0aaac7f99d6",
    "language": "markdown"
   },
   "source": [
    "## 3. Define embedding + LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913c17af9c34c128ecaf81da6c8db3d",
   "metadata": {
    "id": "1913c17af9c34c128ecaf81da6c8db3d",
    "language": "code"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "lstm_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Embedding(input_dim=max_words, output_dim=embedding_dim),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "        tf.keras.layers.Dense(6, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "lstm_model.build((None, max_len))\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2f3fc6c174007b8c6ea785dfd5be8",
   "metadata": {
    "id": "f5d2f3fc6c174007b8c6ea785dfd5be8",
    "language": "markdown"
   },
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a288ccea8145b4bde0850d65b39605",
   "metadata": {
    "id": "50a288ccea8145b4bde0850d65b39605",
    "language": "code"
   },
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lstm_history = lstm_model.fit(\n",
    "    X_train,\n",
    "    y_train_cat,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb70e3daed48d3a0e50a359d211c2d",
   "metadata": {
    "id": "7ebb70e3daed48d3a0e50a359d211c2d",
    "language": "markdown"
   },
   "source": [
    "## 5. Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54aff503ca4518a1f113d029750579",
   "metadata": {
    "id": "fd54aff503ca4518a1f113d029750579",
    "language": "code"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "lstm_probs = lstm_model.predict(X_test)\n",
    "lstm_pred = lstm_probs.argmax(axis=1)\n",
    "\n",
    "lstm_accuracy = accuracy_score(y_test, lstm_pred)\n",
    "lstm_precision, lstm_recall, lstm_f1, _ = precision_recall_fscore_support(\n",
    "    y_test, lstm_pred, average=\"macro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {lstm_accuracy:.4f}\")\n",
    "print(f\"Precision (macro): {lstm_precision:.4f}\")\n",
    "print(f\"Recall (macro): {lstm_recall:.4f}\")\n",
    "print(f\"F1 (macro): {lstm_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, lstm_pred, target_names=class_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50bd43160947ecb4f94a3b7f6831fd",
   "metadata": {
    "id": "5e50bd43160947ecb4f94a3b7f6831fd",
    "language": "markdown"
   },
   "source": [
    "## 6. Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757febd2d94c4113b114583514e1b001",
   "metadata": {
    "id": "757febd2d94c4113b114583514e1b001",
    "language": "code"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "results_dir = Path(\"../results\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "metrics_path = results_dir / \"metrics.csv\"\n",
    "\n",
    "row = {\n",
    "    \"model\": \"RNN_LSTM\",\n",
    "    \"accuracy\": round(lstm_accuracy, 4),\n",
    "    \"precision\": round(lstm_precision, 4),\n",
    "    \"recall\": round(lstm_recall, 4),\n",
    "    \"f1\": round(lstm_f1, 4),\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([row])\n",
    "\n",
    "if metrics_path.exists():\n",
    "    metrics_df.to_csv(metrics_path, mode=\"a\", header=False, index=False)\n",
    "else:\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "print(f\"Saved metrics to: {metrics_path}\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336a9e9474e4ef8be1bd2346f59aa65",
   "metadata": {
    "id": "7336a9e9474e4ef8be1bd2346f59aa65",
    "language": "code"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "val_path = Path(\"../data/validation.txt\")\n",
    "if val_path.exists():\n",
    "    val_df = pd.read_csv(val_path, sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
    "    val_df[\"clean_text\"] = val_df[\"text\"].apply(clean_text)\n",
    "    val_seq = text_tokenizer.texts_to_sequences(val_df[\"clean_text\"])\n",
    "    X_val = pad_sequences(val_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "    y_val = label_encoder.transform(val_df[\"emotion\"])\n",
    "    val_probs = lstm_model.predict(X_val)\n",
    "    val_pred = val_probs.argmax(axis=1)\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n",
    "        y_val, val_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "\n",
    "    print(\"Validation metrics (RNN):\")\n",
    "    print(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Precision (macro): {val_precision:.4f}\")\n",
    "    print(f\"Recall (macro): {val_recall:.4f}\")\n",
    "    print(f\"F1 (macro): {val_f1:.4f}\")\n",
    "\n",
    "    val_row = {\n",
    "        \"model\": \"RNN_LSTM_VAL\",\n",
    "        \"accuracy\": round(val_accuracy, 4),\n",
    "        \"precision\": round(val_precision, 4),\n",
    "        \"recall\": round(val_recall, 4),\n",
    "        \"f1\": round(val_f1, 4),\n",
    "        \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    }\n",
    "\n",
    "    val_metrics_df = pd.DataFrame([val_row])\n",
    "    if metrics_path.exists():\n",
    "        val_metrics_df.to_csv(metrics_path, mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        val_metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "    val_metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
