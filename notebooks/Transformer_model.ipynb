{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4118735258b44758639a66d48aeb21f",
        "language": "markdown"
      },
      "source": [
        "# Model 3: Transformer Fine-Tuning\n",
        "\n",
        "Transformer-based models leverage contextual embeddings learned from large-scale corpora, enabling superior semantic understanding compared to traditional neural architectures.\n",
        "\n",
        "Steps:\n",
        "1. Load raw or lightly cleaned text\n",
        "2. Tokenization with pretrained tokenizer (attention masks)\n",
        "3. Model loading and fine-tuning\n",
        "4. Evaluation on test set\n",
        "5. Save metrics"
      ],
      "id": "e4118735258b44758639a66d48aeb21f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f7d48dde87141e3847edbd9c10b16c0",
        "language": "markdown"
      },
      "source": [
        "## 1. Load raw text"
      ],
      "id": "4f7d48dde87141e3847edbd9c10b16c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80b9768654bf4692922c4009a885b084",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DATA_DIR = Path(\"../data\")\n",
        "\n",
        "train_df = pd.read_csv(DATA_DIR / \"train.txt\", sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
        "test_df = pd.read_csv(DATA_DIR / \"test.txt\", sep=\";\", header=None, names=[\"text\", \"emotion\"])\n",
        "\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
        "test_df[\"clean_text\"] = test_df[\"text\"].apply(clean_text)\n",
        "\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "\n",
        "train_df.head()"
      ],
      "id": "80b9768654bf4692922c4009a885b084"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df16c7bf44864d2fa1be8d32eb8b3fd2",
        "language": "markdown"
      },
      "source": [
        "## 2. Tokenization with pretrained tokenizer"
      ],
      "id": "df16c7bf44864d2fa1be8d32eb8b3fd2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24b100ac606d49719d915d5ffce0e1a7",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "max_length = 128\n",
        "\n",
        "label_names = sorted(train_df[\"emotion\"].unique())\n",
        "label_to_id = {label: idx for idx, label in enumerate(label_names)}\n",
        "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
        "\n",
        "train_df[\"label\"] = train_df[\"emotion\"].map(label_to_id)\n",
        "test_df[\"label\"] = test_df[\"emotion\"].map(label_to_id)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df[[\"clean_text\", \"label\"]])\n",
        "test_dataset = Dataset.from_pandas(test_df[[\"clean_text\", \"label\"]])\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"clean_text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_batch, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_batch, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns([\"clean_text\"])\n",
        "test_dataset = test_dataset.remove_columns([\"clean_text\"])\n",
        "train_dataset.set_format(\"torch\")\n",
        "test_dataset.set_format(\"torch\")\n",
        "\n",
        "print(\"Labels:\", label_names)"
      ],
      "id": "24b100ac606d49719d915d5ffce0e1a7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "311588bb64ef4cada31bf3ec80f97d40",
        "language": "markdown"
      },
      "source": [
        "## 3. Load model and fine-tune"
      ],
      "id": "311588bb64ef4cada31bf3ec80f97d40"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c09c24657954cfa81641047e6eabcd9",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(label_names),\n",
        "    id2label=id_to_label,\n",
        "    label2id=label_to_id,\n",
        ")\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"macro\", zero_division=0\n",
        "    )\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"../results/transformer_checkpoints\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer"
      ],
      "id": "0c09c24657954cfa81641047e6eabcd9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55695ab3feed4b1c9763085643de2fa2",
        "language": "markdown"
      },
      "source": [
        "## 4. Train and evaluate"
      ],
      "id": "55695ab3feed4b1c9763085643de2fa2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "641580679e3341aa82a24432ed180c90",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "train_result = trainer.train()\n",
        "metrics = trainer.evaluate()\n",
        "\n",
        "print(\"Eval metrics:\", metrics)"
      ],
      "id": "641580679e3341aa82a24432ed180c90"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f66c88ac0f544358567e568c067bc11",
        "language": "markdown"
      },
      "source": [
        "## 5. Save metrics"
      ],
      "id": "6f66c88ac0f544358567e568c067bc11"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbb49fc8779e4ab9b5ea8aead9d18acc",
        "language": "code"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "results_dir = Path(\"../results\")\n",
        "results_dir.mkdir(parents=True, exist_ok=True)\n",
        "metrics_path = results_dir / \"metrics.csv\"\n",
        "\n",
        "row = {\n",
        "    \"model\": \"TRANSFORMER\",\n",
        "    \"accuracy\": round(metrics.get(\"eval_accuracy\", 0.0), 4),\n",
        "    \"precision\": round(metrics.get(\"eval_precision\", 0.0), 4),\n",
        "    \"recall\": round(metrics.get(\"eval_recall\", 0.0), 4),\n",
        "    \"f1\": round(metrics.get(\"eval_f1\", 0.0), 4),\n",
        "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame([row])\n",
        "\n",
        "if metrics_path.exists():\n",
        "    metrics_df.to_csv(metrics_path, mode=\"a\", header=False, index=False)\n",
        "else:\n",
        "    metrics_df.to_csv(metrics_path, index=False)\n",
        "\n",
        "print(f\"Saved metrics to: {metrics_path}\")\n",
        "metrics_df"
      ],
      "id": "fbb49fc8779e4ab9b5ea8aead9d18acc"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}